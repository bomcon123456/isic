---

title: Dataset

keywords: fastai
sidebar: home_sidebar

summary: "API details."
description: "API details."
nb_path: "nbs\.ipynb_checkpoints\dataset-checkpoint.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs\.ipynb_checkpoints\dataset-checkpoint.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\bomco\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\utilities\distributed.py:23: UserWarning: Unsupported `ReduceOp` for distributed computing.
  warnings.warn(*args, **kwargs)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SkinLabels" class="doc_header"><code>class</code> <code>SkinLabels</code><a href="https://github.com/termanteus/isic/tree/master/isic/dataset.py#L25" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SkinLabels</code>()</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="preprocess_df" class="doc_header"><code>preprocess_df</code><a href="https://github.com/termanteus/isic/tree/master/isic/dataset.py#L47" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>preprocess_df</code>(<strong><code>df</code></strong>, <strong><code>valid_size</code></strong>=<em><code>0.2</code></em>, <strong><code>seed</code></strong>=<em><code>8080</code></em>, <strong><code>image_label_only</code></strong>=<em><code>False</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SkinDataset" class="doc_header"><code>class</code> <code>SkinDataset</code><a href="https://github.com/termanteus/isic/tree/master/isic/dataset.py#L88" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SkinDataset</code>(<strong><code>df</code></strong>, <strong><code>transform</code></strong>=<em><code>None</code></em>, <strong><code>labels</code></strong>=<em><code>None</code></em>) :: <code>Dataset</code></p>
</blockquote>
<p>An abstract class representing a :class:<code>Dataset</code>.</p>
<p>All datasets that represent a map from keys to data samples should subclass
it. All subclasses should overwrite :meth:<code>__getitem__</code>, supporting fetching a
data sample for a given key. Subclasses could also optionally overwrite
:meth:<code>__len__</code>, which is expected to return the size of the dataset by many
:class:<code>~torch.utils.data.Sampler</code> implementations and the default options
of :class:<code>~torch.utils.data.DataLoader</code>.</p>
<p>.. note::
  :class:<code>~torch.utils.data.DataLoader</code> by default constructs a index
  sampler that yields integral indices.  To make it work with a map-style
  dataset with non-integral indices/keys, a custom sampler must be provided.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SkinDataModule" class="doc_header"><code>class</code> <code>SkinDataModule</code><a href="https://github.com/termanteus/isic/tree/master/isic/dataset.py#L140" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SkinDataModule</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <code>LightningDataModule</code></p>
</blockquote>
<p>A DataModule standardizes the training, val, test splits, data preparation and transforms.
The main advantage is consistent data splits, data preparation and transforms across models.</p>
<p>Example::</p>

<pre><code>class MyDataModule(LightningDataModule):
    def __init__(self):
        super().__init__()
    def prepare_data(self):
        # download, split, etc...
        # only called on 1 GPU/TPU in distributed
    def setup(self):
        # make assignments here (val/train/test split)
        # called on every process in DDP
    def train_dataloader(self):
        train_split = Dataset(...)
        return DataLoader(train_split)
    def val_dataloader(self):
        val_split = Dataset(...)
        return DataLoader(val_split)
    def test_dataloader(self):
        test_split = Dataset(...)
        return DataLoader(test_split)

</code></pre>
<p>A DataModule implements 5 key methods:</p>
<ul>
<li><strong>prepare_data</strong> (things to do on 1 GPU/TPU not on every GPU/TPU in distributed mode).</li>
<li><strong>setup</strong>  (things to do on every accelerator in distributed mode).</li>
<li><strong>train_dataloader</strong> the training dataloader.</li>
<li><strong>val_dataloader</strong> the val dataloader(s).</li>
<li><strong>test_dataloader</strong> the test dataloader(s).</li>
</ul>
<p>This allows you to share a full dataset without explaining how to download,
split transform and process the data</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

