---

title: Models


keywords: fastai
sidebar: home_sidebar

summary: "API details."
description: "API details."
nb_path: "nbs/model.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/model.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2

<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="log_metrics_per_key" class="doc_header"><code>log_metrics_per_key</code><a href="https://github.com/termanteus/isic/tree/master/isic/model.py#L31" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>log_metrics_per_key</code>(<strong><code>logger</code></strong>, <strong><code>metrics</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BaselineModel" class="doc_header"><code>class</code> <code>BaselineModel</code><a href="https://github.com/termanteus/isic/tree/master/isic/model.py#L39" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BaselineModel</code>(<strong><code>arch</code></strong>=<em><code>'resnet50'</code></em>, <strong><code>lr</code></strong>=<em><code>0.01</code></em>) :: <code>LightningModule</code></p>
</blockquote>
<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Model" class="doc_header"><code>class</code> <code>Model</code><a href="https://github.com/termanteus/isic/tree/master/isic/model.py#L140" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Model</code>(<strong><code>lr</code></strong>=<em><code>0.01</code></em>, <strong><code>wd</code></strong>=<em><code>0.0</code></em>, <strong><code>n_out</code></strong>=<em><code>7</code></em>, <strong><code>concat_pool</code></strong>=<em><code>True</code></em>, <strong><code>arch</code></strong>=<em><code>'resnet50'</code></em>) :: <code>LightningModule</code></p>
</blockquote>
<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="fit_one_cycle" class="doc_header"><code>fit_one_cycle</code><a href="https://github.com/termanteus/isic/tree/master/isic/model.py#L269" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>fit_one_cycle</code>(<strong><code>epochs</code></strong>, <strong><code>model</code></strong>, <strong><code>datamodule</code></strong>, <strong><code>opt</code></strong>=<em><code>'Adam'</code></em>, <strong><code>max_lr</code></strong>=<em><code>None</code></em>, <strong><code>pct_start</code></strong>=<em><code>0.25</code></em>, <strong><code>div_factor</code></strong>=<em><code>25.0</code></em>, <strong><code>final_div_factor</code></strong>=<em><code>100000.0</code></em>, <strong><code>wd</code></strong>=<em><code>None</code></em>, <strong><code>skip_bn_wd</code></strong>=<em><code>True</code></em>, <strong><code>max_momentum</code></strong>=<em><code>0.95</code></em>, <strong><code>base_momentum</code></strong>=<em><code>0.85</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">message_formater</span> <span class="o">=</span> <span class="s2">&quot;You have set </span><span class="si">{0}</span><span class="s2"> number of classes if different from predicted </span><span class="si">{0}</span><span class="s2"> and target </span><span class="si">{0}</span><span class="s2"> number of classes&quot;</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message_formater</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;(.*)&quot;</span><span class="p">),</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dm</span> <span class="o">=</span> <span class="n">SkinDataModule</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">F_EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">U_EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">1e-2</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">BaselineModel</span><span class="p">(</span><span class="s1">&#39;resnet18&#39;</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">fast_dev_run</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LogTableMetricsCallback</span><span class="p">()])</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Running in fast_dev_run mode: will run a full train, val and test loop using a single batch
GPU available: False, used: False
TPU available: False, using: 0 TPU cores

  | Name   | Type             | Params
--------------------------------------------
0 | model  | ResNet           | 11 M  
1 | m_bacc | BalancedAccuracy | 0     
&lt;ipython-input-4-32a2040215bc&gt;:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  avg_val_loss = torch.tensor(out.loss).mean()
/home/termanteus/miniconda3/envs/devtorch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:37: RuntimeWarning: The metric you returned None must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of loss in validation_epoch_end()?
  warnings.warn(*args, **kwargs)
/home/termanteus/miniconda3/envs/devtorch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:37: RuntimeWarning: Can save best model only with loss available, skipping.
  warnings.warn(*args, **kwargs)
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>val_loss</th>
      <th>val_acc</th>
      <th>val_balanced_acc</th>
      <th>val_precision</th>
      <th>val_recall</th>
      <th>F1</th>
      <th>val_precision_akiec</th>
      <th>val_precision_bcc</th>
      <th>val_precision_bkl</th>
      <th>val_precision_df</th>
      <th>val_precision_nv</th>
      <th>val_precision_mel</th>
      <th>val_precision_vasc</th>
      <th>val_recal_akiec</th>
      <th>val_recal_bcc</th>
      <th>val_recal_bkl</th>
      <th>val_recal_df</th>
      <th>val_recal_nv</th>
      <th>val_recal_mel</th>
      <th>val_recal_vasc</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>2.045</td>
      <td>44.990627</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table><p>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Saving latest checkpoint..
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">LR</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="s1">&#39;resnet18&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Downloading: &#34;https://download.pytorch.org/models/resnet18-5c106cde.pth&#34; to /home/termanteus/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">check_attrib_module</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
[]
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
AdaptiveAvgPool2d(output_size=1)
[]
AdaptiveMaxPool2d(output_size=1)
[]
Flatten()
[]
BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Dropout(p=0.25, inplace=False)
[]
Linear(in_features=1024, out_features=512, bias=False)
[&#39;weight-requires_grad-True&#39;]
ReLU(inplace=True)
[]
BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Dropout(p=0.5, inplace=False)
[]
Linear(in_features=512, out_features=7, bias=False)
[&#39;weight-requires_grad-True&#39;]
BalancedAccuracy()
[]
LabelSmoothingCrossEntropy()
[]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr_find</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">,</span><span class="n">lr_find</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Running in fast_dev_run mode: will run a full train, val and test loop using a single batch
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
C:\Users\bomco\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\utilities\distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given
  warnings.warn(*args, **kwargs)

  | Name      | Type                       | Params
---------------------------------------------------------
0 | model     | Sequential                 | 11 M  
1 | m_bacc    | BalancedAccuracy           | 0     
2 | loss_func | LabelSmoothingCrossEntropy | 0     
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>override_called
[0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\bomco\miniconda3\envs\devtorch\lib\site-packages\sklearn\metrics\_classification.py:1814: UserWarning: y_pred contains classes not in y_true
  warnings.warn(&#39;y_pred contains classes not in y_true&#39;)
Saving latest checkpoint..
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 3
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 4
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 5
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0
)
******************************Check requires_grad/ skip_wd******************************
Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
[]
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
ReLU(inplace=True)
[]
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
[&#39;weight-requires_grad-False&#39;]
BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
--------------------------------------------------------------------------------
AdaptiveAvgPool2d(output_size=1)
[]
AdaptiveMaxPool2d(output_size=1)
[]
Flatten()
[]
BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Dropout(p=0.25, inplace=False)
[]
Linear(in_features=1024, out_features=512, bias=False)
[&#39;weight-requires_grad-True&#39;]
ReLU(inplace=True)
[]
BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[&#39;weight-requires_grad-True&#39;, &#39;weight-skip_wd-True&#39;, &#39;bias-requires_grad-True&#39;, &#39;bias-skip_wd-True&#39;]
Dropout(p=0.5, inplace=False)
[]
Linear(in_features=512, out_features=7, bias=False)
[&#39;weight-requires_grad-True&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">LogTableMetricsCallback</span><span class="p">(),</span> <span class="n">HyperparamsLogger</span><span class="p">()]</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">F_EPOCHS</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span> <span class="n">fast_dev_run</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">limit_val_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">limit_train_batches</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">unfreeze</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span> <span class="n">fast_dev_run</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">limit_val_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">limit_train_batches</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Running in fast_dev_run mode: will run a full train, val and test loop using a single batch
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
  | Name      | Type             | Params
-----------------------------------------------
0 | model     | Sequential       | 25 M  
1 | loss_func | CrossEntropyLoss | 0     
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>override_called
wtf
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_acc</th>
      <th>val_loss</th>
      <th>val_acc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>3.256</td>
      <td>0.156250</td>
      <td>4.279556</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table><p>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Saving latest checkpoint..
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> tensorboard
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">tensorboard</span> --logdir=lightning_logs/
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea ">
<pre>Reusing TensorBoard on port 6006 (pid 4636), started 4 days, 18:33:26 ago. (Use &#39;!kill 4636&#39; to kill it.)</pre>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

      <iframe id="tensorboard-frame-7752bba96d9fd24c" width="100%" height="800" frameborder="0">
      </iframe>
      <script>
        (function() {
          const frame = document.getElementById("tensorboard-frame-7752bba96d9fd24c");
          const url = new URL("/", window.location);
          url.port = 6006;
          frame.src = url;
        })();
      </script>
  
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nbdev.export</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">notebook2script</span><span class="p">(</span><span class="s1">&#39;model.ipynb&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Converted model.ipynb.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

