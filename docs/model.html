---

title: Models

keywords: fastai
sidebar: home_sidebar

summary: "API details."
description: "API details."
nb_path: "nbs\model.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs\model.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\bomco\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\utilities\distributed.py:23: UserWarning: Unsupported `ReduceOp` for distributed computing.
  warnings.warn(*args, **kwargs)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LabelSmoothingCrossEntropy" class="doc_header"><code>class</code> <code>LabelSmoothingCrossEntropy</code><a href="https://github.com/termanteus/isic/tree/master/isic/model.py#L26" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LabelSmoothingCrossEntropy</code>(<strong><code>eps</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ResnetModel" class="doc_header"><code>class</code> <code>ResnetModel</code><a href="https://github.com/termanteus/isic/tree/master/isic/model.py#L39" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ResnetModel</code>(<strong><code>steps_epoch</code></strong>, <strong><code>epochs</code></strong>=<em><code>30</code></em>, <strong><code>lr</code></strong>=<em><code>0.01</code></em>) :: <code>LightningModule</code></p>
</blockquote>
<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">message_formater</span> <span class="o">=</span> <span class="s2">&quot;You have set </span><span class="si">{0}</span><span class="s2"> number of classes if different from predicted </span><span class="si">{0}</span><span class="s2"> and target </span><span class="si">{0}</span><span class="s2"> number of classes&quot;</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message_formater</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;(.*)&quot;</span><span class="p">),</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dm</span> <span class="o">=</span> <span class="n">SkinDataModule</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">ResnetModel</span><span class="p">(</span><span class="n">steps_epoch</span><span class="o">=</span><span class="mi">140</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="n">hp_log</span> <span class="o">=</span> <span class="n">HyperparamsLogger</span><span class="p">()</span>

<span class="c1"># most basic trainer, uses good defaults</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LogTableMetricsCallback</span><span class="p">(),</span> <span class="n">hp_log</span><span class="p">,</span> <span class="n">CutmixDict</span><span class="p">()],</span> <span class="n">fast_dev_run</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Running in fast_dev_run mode: will run a full train, val and test loop using a single batch
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
  | Name      | Type    | Params
--------------------------------------
0 | resnet    | ResNet  | 23 M  
1 | loss_func | MixLoss | 0     
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>hehe
MixLoss(
  (old_lf): CrossEntropyLoss()
)
hehe
MixLoss(
  (old_lf): CrossEntropyLoss()
)
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_acc</th>
      <th>val_loss</th>
      <th>val_acc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>2.101</td>
      <td>0.046875</td>
      <td>2.057668</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table><p>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> tensorboard
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">tensorboard</span> --logdir=lightning_logs/
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea ">
<pre>Reusing TensorBoard on port 6006 (pid 4636), started 1 day, 1:44:30 ago. (Use &#39;!kill 4636&#39; to kill it.)</pre>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

      <iframe id="tensorboard-frame-e66b67374c344c19" width="100%" height="800" frameborder="0">
      </iframe>
      <script>
        (function() {
          const frame = document.getElementById("tensorboard-frame-e66b67374c344c19");
          const url = new URL("/", window.location);
          url.port = 6006;
          frame.src = url;
        })();
      </script>
  
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>tensorboard --logdir<span class="o">=</span>lightning_logs/
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># class ResnetModel(LightningModule):</span>
<span class="c1">#     def __init__(self):</span>
<span class="c1">#         super().__init__()</span>
<span class="c1"># #         self.save_hyperparameters()</span>
<span class="c1">#         self.resnet = models.resnet50(pretrained=True)</span>
<span class="c1">#         num_ftrs = self.resnet.fc.in_features</span>
<span class="c1">#         self.resnet.fc = nn.Linear(num_ftrs, 7)</span>
<span class="c1">#         self.loss_func = F.cross_entropy</span>

<span class="c1">#     def forward(self, x):</span>
<span class="c1">#         return self.resnet(x)</span>

<span class="c1">#     def training_step(self, batch, batch_idx):</span>
<span class="c1">#         print(batch)</span>
<span class="c1">#         if hasattr(self, &#39;enhanced_batch&#39;):</span>
<span class="c1">#             print(&#39;hehe&#39;)</span>
<span class="c1">#             batch = self.enhanced_batch</span>
<span class="c1">#         x, y = batch</span>
<span class="c1">#         y_hat = self(x)</span>
<span class="c1">#         loss = self.loss_func(y_hat, y)</span>
<span class="c1">#         acc = FM.accuracy(y_hat, y, num_classes=7)</span>
<span class="c1">#         result = pl.TrainResult(minimize=loss)</span>
<span class="c1">#         result.log(&#39;train_loss&#39;, loss)</span>
<span class="c1">#         result.log(&#39;train_acc&#39;, acc, prog_bar=True)</span>
<span class="c1">#         return result</span>

<span class="c1">#     def validation_step(self, batch, batch_idx):</span>
<span class="c1">#         x, y = batch</span>
<span class="c1">#         y_hat = self(x)</span>
<span class="c1">#         loss = F.cross_entropy(y_hat, y)</span>
<span class="c1">#         acc = FM.accuracy(y_hat, y, num_classes=7)</span>
<span class="c1">#         result = pl.EvalResult(checkpoint_on=loss)</span>
<span class="c1">#         result.log(&#39;val_loss&#39;, loss, prog_bar=True) </span>
<span class="c1">#         result.log(&#39;val_acc&#39;, acc, prog_bar=True)</span>
<span class="c1">#         return result</span>

<span class="c1">#     def configure_optimizers(self):</span>
<span class="c1">#         opt = torch.optim.Adam(self.parameters(), lr=1e-2)</span>
<span class="c1">#         scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=1e-2, steps_per_epoch=140, epochs=10)</span>
<span class="c1">#         sched = {</span>
<span class="c1">#             &#39;scheduler&#39;: scheduler, # The LR schduler</span>
<span class="c1">#             &#39;interval&#39;: &#39;step&#39;, # The unit of the scheduler&#39;s step size</span>
<span class="c1">#             &#39;frequency&#39;: 1, # The frequency of the scheduler</span>
<span class="c1">#             &#39;reduce_on_plateau&#39;: False, # For ReduceLROnPlateau scheduler</span>
<span class="c1">#         }</span>
<span class="c1">#         return [opt], [sched]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nbdev</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">notebook2script</span><span class="p">(</span><span class="s1">&#39;model.ipynb&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Converted cb_mixup.ipynb.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

