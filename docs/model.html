---

title: Models

keywords: fastai
sidebar: home_sidebar

summary: "API details."
description: "API details."
nb_path: "nbs\model.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs\model.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\bomco\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\utilities\distributed.py:23: UserWarning: Unsupported `ReduceOp` for distributed computing.
  warnings.warn(*args, **kwargs)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ResnetModel" class="doc_header"><code>class</code> <code>ResnetModel</code><a href="https://github.com/termanteus/isic/tree/master/isic/model.py#L27" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ResnetModel</code>(<strong><code>steps_epoch</code></strong>, <strong><code>epochs</code></strong>=<em><code>30</code></em>, <strong><code>lr</code></strong>=<em><code>0.01</code></em>, <strong><code>weight_decay</code></strong>=<em><code>0.9</code></em>) :: <code>LightningModule</code></p>
</blockquote>
<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">message_formater</span> <span class="o">=</span> <span class="s2">&quot;You have set </span><span class="si">{0}</span><span class="s2"> number of classes if different from predicted </span><span class="si">{0}</span><span class="s2"> and target </span><span class="si">{0}</span><span class="s2"> number of classes&quot;</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message_formater</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;(.*)&quot;</span><span class="p">),</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dm</span> <span class="o">=</span> <span class="n">SkinDataModule</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">ResnetModel</span><span class="p">(</span><span class="n">steps_epoch</span><span class="o">=</span><span class="mi">140</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="n">hp_log</span> <span class="o">=</span> <span class="n">HyperparamsLogger</span><span class="p">()</span>

<span class="c1"># most basic trainer, uses good defaults</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LogTableMetricsCallback</span><span class="p">(),</span> <span class="n">hp_log</span><span class="p">,</span> <span class="n">CutmixDict</span><span class="p">()],</span> <span class="n">fast_dev_run</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>GPU available: False, used: False
TPU available: False, using: 0 TPU cores
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
  | Name      | Type    | Params
--------------------------------------
0 | resnet    | ResNet  | 23 M  
1 | loss_func | MixLoss | 0     
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>MixLoss(
  (old_lf): CrossEntropyLoss()
)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-10-d47d1b932123&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">----&gt; 1</span><span class="ansi-yellow-intense-fg ansi-bold"> </span>trainer<span class="ansi-yellow-intense-fg ansi-bold">.</span>fit<span class="ansi-yellow-intense-fg ansi-bold">(</span>model<span class="ansi-yellow-intense-fg ansi-bold">,</span> dm<span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\trainer\states.py</span> in <span class="ansi-cyan-fg">wrapped_fn</span><span class="ansi-blue-intense-fg ansi-bold">(self, *args, **kwargs)</span>
<span class="ansi-green-fg">     32</span>             <span class="ansi-green-intense-fg ansi-bold">if</span> entering <span class="ansi-green-intense-fg ansi-bold">is</span> <span class="ansi-green-intense-fg ansi-bold">not</span> <span class="ansi-green-intense-fg ansi-bold">None</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">     33</span>                 self<span class="ansi-yellow-intense-fg ansi-bold">.</span>state <span class="ansi-yellow-intense-fg ansi-bold">=</span> entering
<span class="ansi-green-intense-fg ansi-bold">---&gt; 34</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>result <span class="ansi-yellow-intense-fg ansi-bold">=</span> fn<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">*</span>args<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">**</span>kwargs<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     35</span> 
<span class="ansi-green-fg">     36</span>             <span class="ansi-red-intense-fg ansi-bold"># The INTERRUPTED state can be set inside the run function. To indicate that run was interrupted</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\trainer\trainer.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-intense-fg ansi-bold">(self, model, train_dataloader, val_dataloaders, datamodule)</span>
<span class="ansi-green-fg">   1067</span>             self<span class="ansi-yellow-intense-fg ansi-bold">.</span>accelerator_backend <span class="ansi-yellow-intense-fg ansi-bold">=</span> CPUBackend<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1068</span>             self<span class="ansi-yellow-intense-fg ansi-bold">.</span>accelerator_backend<span class="ansi-yellow-intense-fg ansi-bold">.</span>setup<span class="ansi-yellow-intense-fg ansi-bold">(</span>model<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1069</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>results <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>accelerator_backend<span class="ansi-yellow-intense-fg ansi-bold">.</span>train<span class="ansi-yellow-intense-fg ansi-bold">(</span>model<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1070</span> 
<span class="ansi-green-fg">   1071</span>         <span class="ansi-red-intense-fg ansi-bold"># on fit end callback</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\accelerators\cpu_backend.py</span> in <span class="ansi-cyan-fg">train</span><span class="ansi-blue-intense-fg ansi-bold">(self, model)</span>
<span class="ansi-green-fg">     37</span> 
<span class="ansi-green-fg">     38</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> train<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">,</span> model<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">---&gt; 39</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>results <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>trainer<span class="ansi-yellow-intense-fg ansi-bold">.</span>run_pretrain_routine<span class="ansi-yellow-intense-fg ansi-bold">(</span>model<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     40</span>         <span class="ansi-green-intense-fg ansi-bold">return</span> results

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\trainer\trainer.py</span> in <span class="ansi-cyan-fg">run_pretrain_routine</span><span class="ansi-blue-intense-fg ansi-bold">(self, model)</span>
<span class="ansi-green-fg">   1207</span> 
<span class="ansi-green-fg">   1208</span>         <span class="ansi-red-intense-fg ansi-bold"># run a few val batches before training starts</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1209</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_run_sanity_check<span class="ansi-yellow-intense-fg ansi-bold">(</span>ref_model<span class="ansi-yellow-intense-fg ansi-bold">,</span> model<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1210</span> 
<span class="ansi-green-fg">   1211</span>         <span class="ansi-red-intense-fg ansi-bold"># clear cache before training</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\trainer\trainer.py</span> in <span class="ansi-cyan-fg">_run_sanity_check</span><span class="ansi-blue-intense-fg ansi-bold">(self, ref_model, model)</span>
<span class="ansi-green-fg">   1240</span>             num_loaders <span class="ansi-yellow-intense-fg ansi-bold">=</span> len<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>val_dataloaders<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1241</span>             max_batches <span class="ansi-yellow-intense-fg ansi-bold">=</span> <span class="ansi-yellow-intense-fg ansi-bold">[</span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>num_sanity_val_steps<span class="ansi-yellow-intense-fg ansi-bold">]</span> <span class="ansi-yellow-intense-fg ansi-bold">*</span> num_loaders
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1242</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>eval_results <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_evaluate<span class="ansi-yellow-intense-fg ansi-bold">(</span>model<span class="ansi-yellow-intense-fg ansi-bold">,</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>val_dataloaders<span class="ansi-yellow-intense-fg ansi-bold">,</span> max_batches<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-green-intense-fg ansi-bold">False</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1243</span> 
<span class="ansi-green-fg">   1244</span>             <span class="ansi-red-intense-fg ansi-bold"># allow no returns from eval</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\trainer\evaluation_loop.py</span> in <span class="ansi-cyan-fg">_evaluate</span><span class="ansi-blue-intense-fg ansi-bold">(self, model, dataloaders, max_batches, test_mode)</span>
<span class="ansi-green-fg">    331</span>                         output <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>evaluation_forward<span class="ansi-yellow-intense-fg ansi-bold">(</span>model<span class="ansi-yellow-intense-fg ansi-bold">,</span> batch<span class="ansi-yellow-intense-fg ansi-bold">,</span> batch_idx<span class="ansi-yellow-intense-fg ansi-bold">,</span> dataloader_idx<span class="ansi-yellow-intense-fg ansi-bold">,</span> test_mode<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    332</span>                 <span class="ansi-green-intense-fg ansi-bold">else</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 333</span><span class="ansi-yellow-intense-fg ansi-bold">                     </span>output <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>evaluation_forward<span class="ansi-yellow-intense-fg ansi-bold">(</span>model<span class="ansi-yellow-intense-fg ansi-bold">,</span> batch<span class="ansi-yellow-intense-fg ansi-bold">,</span> batch_idx<span class="ansi-yellow-intense-fg ansi-bold">,</span> dataloader_idx<span class="ansi-yellow-intense-fg ansi-bold">,</span> test_mode<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    334</span> 
<span class="ansi-green-fg">    335</span>                 is_result_obj <span class="ansi-yellow-intense-fg ansi-bold">=</span> isinstance<span class="ansi-yellow-intense-fg ansi-bold">(</span>output<span class="ansi-yellow-intense-fg ansi-bold">,</span> Result<span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\devtorch\lib\site-packages\pytorch_lightning\trainer\evaluation_loop.py</span> in <span class="ansi-cyan-fg">evaluation_forward</span><span class="ansi-blue-intense-fg ansi-bold">(self, model, batch, batch_idx, dataloader_idx, test_mode)</span>
<span class="ansi-green-fg">    680</span>             output <span class="ansi-yellow-intense-fg ansi-bold">=</span> model<span class="ansi-yellow-intense-fg ansi-bold">.</span>test_step<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">*</span>args<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    681</span>         <span class="ansi-green-intense-fg ansi-bold">else</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 682</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>output <span class="ansi-yellow-intense-fg ansi-bold">=</span> model<span class="ansi-yellow-intense-fg ansi-bold">.</span>validation_step<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">*</span>args<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    683</span> 
<span class="ansi-green-fg">    684</span>         <span class="ansi-green-intense-fg ansi-bold">return</span> output

<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-4-9401fb3ff232&gt;</span> in <span class="ansi-cyan-fg">validation_step</span><span class="ansi-blue-intense-fg ansi-bold">(self, batch, batch_idx)</span>
<span class="ansi-green-fg">     27</span>         y_hat <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">(</span>x<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     28</span>         print<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>loss_func<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">---&gt; 29</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>loss <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>loss_func<span class="ansi-yellow-intense-fg ansi-bold">(</span>y_hat<span class="ansi-yellow-intense-fg ansi-bold">,</span> y<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     30</span>         acc <span class="ansi-yellow-intense-fg ansi-bold">=</span> FM<span class="ansi-yellow-intense-fg ansi-bold">.</span>accuracy<span class="ansi-yellow-intense-fg ansi-bold">(</span>y_hat<span class="ansi-yellow-intense-fg ansi-bold">,</span> y<span class="ansi-yellow-intense-fg ansi-bold">,</span> num_classes<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">7</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     31</span>         result <span class="ansi-yellow-intense-fg ansi-bold">=</span> pl<span class="ansi-yellow-intense-fg ansi-bold">.</span>EvalResult<span class="ansi-yellow-intense-fg ansi-bold">(</span>checkpoint_on<span class="ansi-yellow-intense-fg ansi-bold">=</span>loss<span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\devtorch\lib\site-packages\torch\nn\modules\module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-intense-fg ansi-bold">(self, *input, **kwargs)</span>
<span class="ansi-green-fg">    720</span>             result <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_slow_forward<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">*</span>input<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">**</span>kwargs<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    721</span>         <span class="ansi-green-intense-fg ansi-bold">else</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 722</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>result <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>forward<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">*</span>input<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">**</span>kwargs<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    723</span>         for hook in itertools.chain(
<span class="ansi-green-fg">    724</span>                 _global_forward_hooks<span class="ansi-yellow-intense-fg ansi-bold">.</span>values<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">,</span>

<span class="ansi-green-intense-fg ansi-bold">d:\workspace\ml\ham10000\isic\isic\layers.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-intense-fg ansi-bold">(self, pred, yb)</span>
<span class="ansi-green-fg">     30</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>mixup_cb<span class="ansi-yellow-intense-fg ansi-bold">.</span>pl_module<span class="ansi-yellow-intense-fg ansi-bold">.</span>testing<span class="ansi-yellow-intense-fg ansi-bold">:</span> <span class="ansi-green-intense-fg ansi-bold">return</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>old_lf<span class="ansi-yellow-intense-fg ansi-bold">(</span>pred<span class="ansi-yellow-intense-fg ansi-bold">,</span> yb<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     31</span>         <span class="ansi-green-intense-fg ansi-bold">with</span> NoneReduce<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>old_lf<span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-green-intense-fg ansi-bold">as</span> lf<span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">---&gt; 32</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>mixup_cb<span class="ansi-yellow-intense-fg ansi-bold">.</span>yb_1 <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>mixup_cb<span class="ansi-yellow-intense-fg ansi-bold">.</span>yb_1<span class="ansi-yellow-intense-fg ansi-bold">.</span>to<span class="ansi-yellow-intense-fg ansi-bold">(</span>pred<span class="ansi-yellow-intense-fg ansi-bold">.</span>device<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     33</span>             self<span class="ansi-yellow-intense-fg ansi-bold">.</span>mixup_cb<span class="ansi-yellow-intense-fg ansi-bold">.</span>lam <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>mixup_cb<span class="ansi-yellow-intense-fg ansi-bold">.</span>lam<span class="ansi-yellow-intense-fg ansi-bold">.</span>to<span class="ansi-yellow-intense-fg ansi-bold">(</span>pred<span class="ansi-yellow-intense-fg ansi-bold">.</span>device<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     34</span>             loss <span class="ansi-yellow-intense-fg ansi-bold">=</span> torch<span class="ansi-yellow-intense-fg ansi-bold">.</span>lerp<span class="ansi-yellow-intense-fg ansi-bold">(</span>lf<span class="ansi-yellow-intense-fg ansi-bold">(</span>pred<span class="ansi-yellow-intense-fg ansi-bold">,</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>mixup_cb<span class="ansi-yellow-intense-fg ansi-bold">.</span>yb_1<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> lf<span class="ansi-yellow-intense-fg ansi-bold">(</span>pred<span class="ansi-yellow-intense-fg ansi-bold">,</span>yb<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>mixup_cb<span class="ansi-yellow-intense-fg ansi-bold">.</span>lam<span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-red-intense-fg ansi-bold">AttributeError</span>: &#39;CutmixDict&#39; object has no attribute &#39;yb_1&#39;</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> tensorboard
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">tensorboard</span> --logdir=lightning_logs/
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea ">
<pre>Reusing TensorBoard on port 6006 (pid 4636), started 1 day, 1:44:30 ago. (Use &#39;!kill 4636&#39; to kill it.)</pre>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

      <iframe id="tensorboard-frame-e66b67374c344c19" width="100%" height="800" frameborder="0">
      </iframe>
      <script>
        (function() {
          const frame = document.getElementById("tensorboard-frame-e66b67374c344c19");
          const url = new URL("/", window.location);
          url.port = 6006;
          frame.src = url;
        })();
      </script>
  
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>tensorboard --logdir<span class="o">=</span>lightning_logs/
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># class ResnetModel(LightningModule):</span>
<span class="c1">#     def __init__(self):</span>
<span class="c1">#         super().__init__()</span>
<span class="c1"># #         self.save_hyperparameters()</span>
<span class="c1">#         self.resnet = models.resnet50(pretrained=True)</span>
<span class="c1">#         num_ftrs = self.resnet.fc.in_features</span>
<span class="c1">#         self.resnet.fc = nn.Linear(num_ftrs, 7)</span>
<span class="c1">#         self.loss_func = F.cross_entropy</span>

<span class="c1">#     def forward(self, x):</span>
<span class="c1">#         return self.resnet(x)</span>

<span class="c1">#     def training_step(self, batch, batch_idx):</span>
<span class="c1">#         print(batch)</span>
<span class="c1">#         if hasattr(self, &#39;enhanced_batch&#39;):</span>
<span class="c1">#             print(&#39;hehe&#39;)</span>
<span class="c1">#             batch = self.enhanced_batch</span>
<span class="c1">#         x, y = batch</span>
<span class="c1">#         y_hat = self(x)</span>
<span class="c1">#         loss = self.loss_func(y_hat, y)</span>
<span class="c1">#         acc = FM.accuracy(y_hat, y, num_classes=7)</span>
<span class="c1">#         result = pl.TrainResult(minimize=loss)</span>
<span class="c1">#         result.log(&#39;train_loss&#39;, loss)</span>
<span class="c1">#         result.log(&#39;train_acc&#39;, acc, prog_bar=True)</span>
<span class="c1">#         return result</span>

<span class="c1">#     def validation_step(self, batch, batch_idx):</span>
<span class="c1">#         x, y = batch</span>
<span class="c1">#         y_hat = self(x)</span>
<span class="c1">#         loss = F.cross_entropy(y_hat, y)</span>
<span class="c1">#         acc = FM.accuracy(y_hat, y, num_classes=7)</span>
<span class="c1">#         result = pl.EvalResult(checkpoint_on=loss)</span>
<span class="c1">#         result.log(&#39;val_loss&#39;, loss, prog_bar=True) </span>
<span class="c1">#         result.log(&#39;val_acc&#39;, acc, prog_bar=True)</span>
<span class="c1">#         return result</span>

<span class="c1">#     def configure_optimizers(self):</span>
<span class="c1">#         opt = torch.optim.Adam(self.parameters(), lr=1e-2)</span>
<span class="c1">#         scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=1e-2, steps_per_epoch=140, epochs=10)</span>
<span class="c1">#         sched = {</span>
<span class="c1">#             &#39;scheduler&#39;: scheduler, # The LR schduler</span>
<span class="c1">#             &#39;interval&#39;: &#39;step&#39;, # The unit of the scheduler&#39;s step size</span>
<span class="c1">#             &#39;frequency&#39;: 1, # The frequency of the scheduler</span>
<span class="c1">#             &#39;reduce_on_plateau&#39;: False, # For ReduceLROnPlateau scheduler</span>
<span class="c1">#         }</span>
<span class="c1">#         return [opt], [sched]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nbdev.export</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">notebook2script</span><span class="p">(</span><span class="s1">&#39;model.ipynb&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Converted cb_mixup.ipynb.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

