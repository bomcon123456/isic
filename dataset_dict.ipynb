{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bomco\\miniconda3\\envs\\devtorch\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: UserWarning: Unsupported `ReduceOp` for distributed computing.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from isic.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SkinLabels():\n",
    "    lesion_type_dict = {\n",
    "        'nv': 'Melanocytic nevi',\n",
    "        'mel': 'Melanoma',\n",
    "        'bkl': 'Benign keratosis-like lesions ',\n",
    "        'bcc': 'Basal cell carcinoma',\n",
    "        'akiec': 'Actinic keratoses',\n",
    "        'vasc': 'Vascular lesions',\n",
    "        'df': 'Dermatofibroma'\n",
    "    }\n",
    "\n",
    "    lesion_type_vi_dict = {\n",
    "        'nv': 'Nốt ruồi',\n",
    "        'mel': 'Ung thư hắc tố',\n",
    "        'bkl': 'U sừng hóa ác tính ',\n",
    "        'bcc': 'U da ung thư tế bào đáy',\n",
    "        'akiec': 'Dày sừng quang hóa',\n",
    "        'vasc': 'Thương tổn mạch máu',\n",
    "        'df': 'U da lành tính'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def preprocess_df(df, valid_size=0.2, seed=AppConfig.SEED, image_label_only=False, img_path = PathConfig.IMAGE_PATH):\n",
    "\n",
    "    df['path'] = img_path + '/' + df['image_id'] + '.jpg'\n",
    "    df['label_fullstr'] = df['dx'].map(SkinLabels.lesion_type_dict.get)\n",
    "\n",
    "    label_str = pd.Categorical(df['label_fullstr'])\n",
    "    df['label_index'] = label_str.codes\n",
    "\n",
    "    df_undup = df.groupby('lesion_id').count()\n",
    "    df_undup = df_undup[df_undup['image_id'] == 1]\n",
    "    df_undup.reset_index(inplace=True)\n",
    "\n",
    "    _, valid = train_test_split(df_undup['lesion_id'], test_size=valid_size, \n",
    "                                random_state=seed, \n",
    "                                stratify=df_undup['label_index'])\n",
    "    valid = set(valid)\n",
    "    df['val'] = df['lesion_id'].apply(lambda x: 1 if str(x) in valid else 0)\n",
    "\n",
    "    df_train = df[df['val'] == 0]\n",
    "    df_valid = df[df['val'] == 1]\n",
    "\n",
    "    dest_df_train = df_train.reset_index(drop=True)\n",
    "    dest_df_valid = df_valid.reset_index(drop=True)\n",
    "    if not image_label_only:\n",
    "        return dest_df_train, dest_df_valid, list(label_str.categories)\n",
    "    else:\n",
    "        train_imgs = []\n",
    "        val_imgs = []\n",
    "        i = 0\n",
    "        for df in (dest_df_train, dest_df_valid):\n",
    "            for j, path in enumerate(df['path']):\n",
    "                x = np.array(Image.open(path))\n",
    "                y = torch.tensor(int(df['label_index'][j]))\n",
    "                if i == 0:\n",
    "                    train_imgs.append((x, y))\n",
    "                else:\n",
    "                    val_imgs.append((x, y))\n",
    "            i += 1\n",
    "        return train_imgs, val_imgs, list(label_str.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, labels=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i >= len(self): raise IndexError\n",
    "        x = Image.open(self.df['path'][i])\n",
    "        y = torch.tensor(int(self.df['label_index'][i]))\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return {\"img\": x, \"label\": y}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def show_image(self, index=None):\n",
    "        dataset = self\n",
    "        n_samples = len(dataset)\n",
    "\n",
    "        if not index:\n",
    "            index = int(np.random.random()*n_samples)\n",
    "        else:\n",
    "            if index >= n_samples or index < 0:\n",
    "                print('Invalid index.')\n",
    "                return\n",
    "\n",
    "        d = dataset[index]\n",
    "\n",
    "        plt.imshow(d['img'].permute(1,2,0))\n",
    "        plt.axis('off')\n",
    "        plt.title(self.labels[d['label']] if self.labels else d['label'])\n",
    "\n",
    "    def show_grid(self, n_rows=5, n_cols=5):\n",
    "        dataset = self\n",
    "        array = torch.utils.data.Subset(dataset, np.random.choice(len(dataset), n_rows*n_cols, replace=False))\n",
    "\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        for row in range(n_rows):\n",
    "            for col in range(n_cols):\n",
    "                index = n_cols * row + col\n",
    "                plt.subplot(n_rows, n_cols, index + 1)\n",
    "                plt.imshow(array[index]['img'].permute(1, 2, 0))\n",
    "                plt.axis('off')\n",
    "                label = self.labels[int(array[index]['label'])] if self.labels else int(array[index]['label'])\n",
    "                plt.title(label, fontsize=12)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SkinDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, df_path=PathConfig.CSV_PATH, transform=None, valid_size=0.2, bs=64):\n",
    "        self.df_path = df_path\n",
    "        self.valid_size = 0.2\n",
    "        self.bs = bs\n",
    "        if not transform:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.7579628, 0.5485365, 0.5737883],\n",
    "                                     std=[0.1419983, 0.15297663, 0.17065412])\n",
    "            ])\n",
    "\n",
    "        self.dims = (3, 224, 224)\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            df = pd.read_csv(self.df_path)\n",
    "            train_df, valid_df, self.labels = preprocess_df(df, self.valid_size)\n",
    "            self.train_ds = SkinDataset(train_df, self.transform, self.labels)\n",
    "            self.val_ds = SkinDataset(valid_df, self.transform, self.labels)\n",
    "\n",
    "            self.dims = tuple(self.train_ds[0][\"img\"].shape)\n",
    "\n",
    "        if stage == 'test':\n",
    "            #TODO\n",
    "            pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.bs, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.bs, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        #TODO\n",
    "        return DataLoader(self.val_ds, batch_size=self.bs, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted dataset_dict.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script('dataset_dict.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
