{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hook\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from isic.utils.core import reduce_loss, generate_val_steps, is_listy, to_detach, apply, PrettyString\n",
    "from isic.utils.model import flatten_model, in_channels, one_param, create_body, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Hook:\n",
    "    def __init__(self, m, hook_func, is_forward=True, detach=True, cpu=False):\n",
    "        self.hook_func = hook_func\n",
    "        self.detach = detach\n",
    "        self.cpu = cpu\n",
    "        f = m.register_forward_hook if is_forward else m.register_backward_hook\n",
    "        self.hook = f(self.hook_fn)\n",
    "        self.stored, self.removed = None, False\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        if self.detach:\n",
    "            input, output = to_detach(input, cpu=self.cpu), to_detach(output, cpu=self.cpu)\n",
    "        self.stored = self.hook_func(module, input, output)\n",
    "\n",
    "    def remove(self):\n",
    "        if not self.removed:\n",
    "            self.hook.remove()\n",
    "            self.removed = True\n",
    "\n",
    "    def __enter__(self, *args): return self\n",
    "    def __exit__(self, *args): self.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Hooks:\n",
    "    def __init__(self, ms, hook_func, is_forward=True, detach=True, cpu=False):\n",
    "        self.hooks = [Hook(m, hook_func, is_forward, detach, cpu) for m in ms]\n",
    "\n",
    "    def __getitem__(self, i): return self.hooks[i]\n",
    "    def __len__(self): return len(self.hooks)\n",
    "    def __iter__(self): return iter(self.hooks)\n",
    "    \n",
    "    @property\n",
    "    def stored(self): return list([o.stored for o in self])\n",
    "\n",
    "    def remove(self):\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "\n",
    "    def __enter__(self, *args): return self\n",
    "    def __exit__(self, *args): self.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _hook_inner(m,i,o): \n",
    "    \"Function that returns ouput of a layer.\"\n",
    "    return o if isinstance(o, Tensor) or is_listy(o) else list(o)\n",
    "\n",
    "def hook_output(module, detach=True, cpu=False, grad=False):\n",
    "    \"Return a `Hook` that stores outputs of `module` in `self.stored`\"\n",
    "    return Hook(module, _hook_inner, detach=detach, cpu=cpu, is_forward=not grad)\n",
    "\n",
    "def hook_outputs(modules, detach=True, cpu=False, grad=False):\n",
    "    \"Return `Hooks` that store outputs of all `modules` in `self.stored`\"\n",
    "    return Hooks(modules, _hook_inner, detach=detach, cpu=cpu, is_forward=not grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dummy_eval(m, size=(64,64)):\n",
    "    \"Evaluate `m` on a dummy input of a certain `size`\"\n",
    "    ch_in = in_channels(m)\n",
    "    x = one_param(m).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.,1.)\n",
    "    with torch.no_grad(): return m.eval()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def model_sizes(m, size=(64,64)):\n",
    "    \"Pass a dummy input through the model `m` to get the output size of each layers.\"\n",
    "    with hook_outputs(m) as hooks:\n",
    "        _ = dummy_eval(m, size=size)\n",
    "        return [o.stored.shape for o in hooks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def num_features_model(m):\n",
    "    \"Return the number of output features for `m`.\"\n",
    "    sz,ch_in = 32,in_channels(m)\n",
    "    while True:\n",
    "        #Trying for a few sizes in case the model requires a big input size.\n",
    "        try:\n",
    "            return model_sizes(m, (sz,sz))[-1][1]\n",
    "        except Exception as e:\n",
    "            sz *= 2\n",
    "            if sz > 2048: raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def layer_info(model, xb):\n",
    "    \"Return layer infos of `model` on `xb`\"\n",
    "    def _track(m, i, o): return (m.__class__.__name__,)+total_params(m)+(apply(lambda x:x.shape, o),)\n",
    "    with Hooks(flatten_model(model), _track) as h:\n",
    "        batch = apply(lambda o:o[:1], xb)\n",
    "        r = model.eval()(batch)\n",
    "        return h.stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _print_shapes(o, bs):\n",
    "    \"Print shape with format BS x CHANNELS x HEIGHT x WIDTH\"\n",
    "    if isinstance(o, torch.Size): return ' x '.join([str(bs)] + [str(t) for t in o[1:]])\n",
    "    else: return str([_print_shapes(x, bs) for x in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def module_summary(model, bs=64, size=(3, 64, 64)):\n",
    "    \"Print a summary (input/output of each layer, #params, trainabled) of `model` depends on the `size` of a batch\"\n",
    "    xb = torch.rand(bs, *size)\n",
    "    infos = layer_info(model, xb)\n",
    "    line_size = 64\n",
    "    inp_sz = _print_shapes(apply(lambda x:x.shape, xb), bs)\n",
    "    res = f\"{model.__class__.__name__} (Input shape: {inp_sz})\\n\"\n",
    "    res += \"=\" * line_size + \"\\n\"\n",
    "    res += f\"{'Layer (type)':<20} {'Output Shape':<20} {'Param #':<10} {'Trainable':<10}\\n\"\n",
    "    res += \"=\" * line_size + \"\\n\"\n",
    "    ps,trn_ps = 0,0\n",
    "    infos = [o for o in infos if o is not None] #see comment in previous cell\n",
    "    for typ,np,trn,sz in infos:\n",
    "        if sz is None: continue\n",
    "        ps += np\n",
    "        if trn: trn_ps += np\n",
    "        res += f\"{typ:<20} {_print_shapes(sz, bs)[:19]:<20} {np:<10,} {str(trn):<10}\\n\"\n",
    "        res += \"_\" * line_size + \"\\n\"\n",
    "    res += f\"\\nTotal params: {ps:,}\\n\"\n",
    "    res += f\"Total trainable params: {trn_ps:,}\\n\"\n",
    "    res += f\"Total non-trainable params: {ps - trn_ps:,}\\n\\n\"\n",
    "    return PrettyString(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd, a, b = create_body('resnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 64, 32, 32]),\n",
       " torch.Size([1, 64, 32, 32]),\n",
       " torch.Size([1, 64, 32, 32]),\n",
       " torch.Size([1, 64, 16, 16]),\n",
       " torch.Size([1, 64, 16, 16]),\n",
       " torch.Size([1, 128, 8, 8]),\n",
       " torch.Size([1, 256, 4, 4]),\n",
       " torch.Size([1, 512, 2, 2])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sizes(bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features_model(bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Conv2d', 9408, True, torch.Size([1, 64, 112, 112])),\n",
       " ('BatchNorm2d', 128, True, torch.Size([1, 64, 112, 112])),\n",
       " ('ReLU', 0, False, torch.Size([1, 64, 112, 112])),\n",
       " ('MaxPool2d', 0, False, torch.Size([1, 64, 56, 56])),\n",
       " ('Conv2d', 36864, True, torch.Size([1, 64, 56, 56])),\n",
       " ('BatchNorm2d', 128, True, torch.Size([1, 64, 56, 56])),\n",
       " ('ReLU', 0, False, torch.Size([1, 64, 56, 56])),\n",
       " ('Conv2d', 36864, True, torch.Size([1, 64, 56, 56])),\n",
       " ('BatchNorm2d', 128, True, torch.Size([1, 64, 56, 56])),\n",
       " ('Conv2d', 36864, True, torch.Size([1, 64, 56, 56])),\n",
       " ('BatchNorm2d', 128, True, torch.Size([1, 64, 56, 56])),\n",
       " ('ReLU', 0, False, torch.Size([1, 64, 56, 56])),\n",
       " ('Conv2d', 36864, True, torch.Size([1, 64, 56, 56])),\n",
       " ('BatchNorm2d', 128, True, torch.Size([1, 64, 56, 56])),\n",
       " ('Conv2d', 73728, True, torch.Size([1, 128, 28, 28])),\n",
       " ('BatchNorm2d', 256, True, torch.Size([1, 128, 28, 28])),\n",
       " ('ReLU', 0, False, torch.Size([1, 128, 28, 28])),\n",
       " ('Conv2d', 147456, True, torch.Size([1, 128, 28, 28])),\n",
       " ('BatchNorm2d', 256, True, torch.Size([1, 128, 28, 28])),\n",
       " ('Conv2d', 8192, True, torch.Size([1, 128, 28, 28])),\n",
       " ('BatchNorm2d', 256, True, torch.Size([1, 128, 28, 28])),\n",
       " ('Conv2d', 147456, True, torch.Size([1, 128, 28, 28])),\n",
       " ('BatchNorm2d', 256, True, torch.Size([1, 128, 28, 28])),\n",
       " ('ReLU', 0, False, torch.Size([1, 128, 28, 28])),\n",
       " ('Conv2d', 147456, True, torch.Size([1, 128, 28, 28])),\n",
       " ('BatchNorm2d', 256, True, torch.Size([1, 128, 28, 28])),\n",
       " ('Conv2d', 294912, True, torch.Size([1, 256, 14, 14])),\n",
       " ('BatchNorm2d', 512, True, torch.Size([1, 256, 14, 14])),\n",
       " ('ReLU', 0, False, torch.Size([1, 256, 14, 14])),\n",
       " ('Conv2d', 589824, True, torch.Size([1, 256, 14, 14])),\n",
       " ('BatchNorm2d', 512, True, torch.Size([1, 256, 14, 14])),\n",
       " ('Conv2d', 32768, True, torch.Size([1, 256, 14, 14])),\n",
       " ('BatchNorm2d', 512, True, torch.Size([1, 256, 14, 14])),\n",
       " ('Conv2d', 589824, True, torch.Size([1, 256, 14, 14])),\n",
       " ('BatchNorm2d', 512, True, torch.Size([1, 256, 14, 14])),\n",
       " ('ReLU', 0, False, torch.Size([1, 256, 14, 14])),\n",
       " ('Conv2d', 589824, True, torch.Size([1, 256, 14, 14])),\n",
       " ('BatchNorm2d', 512, True, torch.Size([1, 256, 14, 14])),\n",
       " ('Conv2d', 1179648, True, torch.Size([1, 512, 7, 7])),\n",
       " ('BatchNorm2d', 1024, True, torch.Size([1, 512, 7, 7])),\n",
       " ('ReLU', 0, False, torch.Size([1, 512, 7, 7])),\n",
       " ('Conv2d', 2359296, True, torch.Size([1, 512, 7, 7])),\n",
       " ('BatchNorm2d', 1024, True, torch.Size([1, 512, 7, 7])),\n",
       " ('Conv2d', 131072, True, torch.Size([1, 512, 7, 7])),\n",
       " ('BatchNorm2d', 1024, True, torch.Size([1, 512, 7, 7])),\n",
       " ('Conv2d', 2359296, True, torch.Size([1, 512, 7, 7])),\n",
       " ('BatchNorm2d', 1024, True, torch.Size([1, 512, 7, 7])),\n",
       " ('ReLU', 0, False, torch.Size([1, 512, 7, 7])),\n",
       " ('Conv2d', 2359296, True, torch.Size([1, 512, 7, 7])),\n",
       " ('BatchNorm2d', 1024, True, torch.Size([1, 512, 7, 7]))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = torch.rand(64, 3, 224, 224)\n",
    "li = layer_info(bd, xb)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'64 x 64 x 112 x 112'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_print_shapes(li[0][3], 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (Input shape: 64 x 3 x 224 x 224)\n",
       "================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "================================================================\n",
       "Conv2d               64 x 64 x 112 x 112  9,408      True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 112 x 112  128        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 64 x 112 x 112  0          False     \n",
       "________________________________________________________________\n",
       "MaxPool2d            64 x 64 x 56 x 56    0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 56 x 56    36,864     True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 56 x 56    128        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 64 x 56 x 56    0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 56 x 56    36,864     True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 56 x 56    128        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 56 x 56    36,864     True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 56 x 56    128        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 64 x 56 x 56    0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 56 x 56    36,864     True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 56 x 56    128        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 28 x 28   73,728     True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 28 x 28   256        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 128 x 28 x 28   0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 28 x 28   147,456    True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 28 x 28   256        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 28 x 28   8,192      True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 28 x 28   256        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 28 x 28   147,456    True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 28 x 28   256        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 128 x 28 x 28   0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 28 x 28   147,456    True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 28 x 28   256        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 14 x 14   294,912    True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 14 x 14   512        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 256 x 14 x 14   0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 14 x 14   589,824    True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 14 x 14   512        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 14 x 14   32,768     True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 14 x 14   512        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 14 x 14   589,824    True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 14 x 14   512        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 256 x 14 x 14   0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 14 x 14   589,824    True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 14 x 14   512        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 7 x 7     1,179,648  True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 7 x 7     1,024      True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 512 x 7 x 7     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 7 x 7     2,359,296  True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 7 x 7     1,024      True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 7 x 7     131,072    True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 7 x 7     1,024      True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 7 x 7     2,359,296  True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 7 x 7     1,024      True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 512 x 7 x 7     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 7 x 7     2,359,296  True      \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 7 x 7     1,024      True      \n",
       "________________________________________________________________\n",
       "\n",
       "Total params: 11,176,512\n",
       "Total trainable params: 11,176,512\n",
       "Total non-trainable params: 0\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_summary(bd, size=(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
