{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Utils\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "\n",
    "from isic.config import *\n",
    "from isic.sampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SkinLabels:\n",
    "    lesion_type_dict = {\n",
    "        'nv': 'Melanocytic nevi',\n",
    "        'mel': 'Melanoma',\n",
    "        'bkl': 'Benign keratosis-like lesions',\n",
    "        'bcc': 'Basal cell carcinoma',\n",
    "        'akiec': 'Actinic keratoses',\n",
    "        'vasc': 'Vascular lesions',\n",
    "        'df': 'Dermatofibroma'\n",
    "    }\n",
    "    \n",
    "    lesion_type_dict_inversed = {\n",
    "      'Melanocytic nevi': 'nv',\n",
    "      'Melanoma': 'mel',\n",
    "      'Benign keratosis-like lesions': 'bkl',\n",
    "      'Basal cell carcinoma': 'bcc',\n",
    "      'Actinic keratoses': 'akiec',\n",
    "      'Vascular lesions': 'vasc',\n",
    "      'Dermatofibroma': 'df'\n",
    "    }\n",
    "\n",
    "    lesion_type_vi_dict = {\n",
    "        'nv': 'Nốt ruồi',\n",
    "        'mel': 'Ung thư hắc tố',\n",
    "        'bkl': 'Dày sừng lành tính',\n",
    "        'bcc': 'Ung thư biểu mô tế bào đáy',\n",
    "        'akiec': 'Dày sừng quang hóa',\n",
    "        'vasc': 'Thương tổn mạch máu',\n",
    "        'df': 'U xơ da'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def from_label_idx_to_key(label_idx, labels):\n",
    "    label_string = labels[label_idx]\n",
    "    key = SkinLabels.lesion_type_dict_inversed[label_string]\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def preprocess_df(df, valid_size=0.2, seed=AppConfig.SEED, image_label_only=False, img_path = PathConfig.IMAGE_PATH):\n",
    "\n",
    "    df['age'].fillna((df['age'].mean()), inplace=True)\n",
    "    \n",
    "    df['path'] = img_path + '/' + df['image_id'] + '.jpg'\n",
    "    df['label_fullstr'] = df['dx'].map(SkinLabels.lesion_type_dict.get)\n",
    "\n",
    "    label_str = pd.Categorical(df['label_fullstr'])\n",
    "    df['label_index'] = label_str.codes\n",
    "\n",
    "    df_undup = df.groupby('lesion_id').count()\n",
    "    df_undup = df_undup[df_undup['image_id'] == 1]\n",
    "    df_undup.reset_index(inplace=True)\n",
    "\n",
    "    _, valid = train_test_split(df_undup['lesion_id'], test_size=valid_size, \n",
    "                                random_state=seed, \n",
    "                                stratify=df_undup['label_index'])\n",
    "    valid = set(valid)\n",
    "    df['val'] = df['lesion_id'].apply(lambda x: 1 if str(x) in valid else 0)\n",
    "\n",
    "    df_train = df[df['val'] == 0]\n",
    "    df_valid = df[df['val'] == 1]\n",
    "\n",
    "    dest_df_train = df_train.reset_index(drop=True)\n",
    "    dest_df_valid = df_valid.reset_index(drop=True)\n",
    "    if not image_label_only:\n",
    "        return dest_df_train, dest_df_valid, list(label_str.categories)\n",
    "    else:\n",
    "        train_imgs = []\n",
    "        val_imgs = []\n",
    "        i = 0\n",
    "        for df in (dest_df_train, dest_df_valid):\n",
    "            for j, path in enumerate(df['path']):\n",
    "                x = np.array(Image.open(path))\n",
    "                y = torch.tensor(int(df['label_index'][j]))\n",
    "                if i == 0:\n",
    "                    train_imgs.append((x, y))\n",
    "                else:\n",
    "                    val_imgs.append((x, y))\n",
    "            i += 1\n",
    "        return train_imgs, val_imgs, list(label_str.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_default_train_transform(image_size=224, no_norm=False):\n",
    "    transforms_train = [\n",
    "        A.Transpose(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Resize(400, 400),\n",
    "        A.RandomResizedCrop(image_size, image_size)\n",
    "    ]\n",
    "    norm = A.Normalize()\n",
    "    if no_norm:\n",
    "        norm = A.Normalize(mean=0, std=1)\n",
    "    transforms_train.append(norm)\n",
    "    return A.Compose(transforms_train)\n",
    "\n",
    "def get_advanced_train_transform(image_size=224, cut_out=True, no_norm=False):\n",
    "    transforms_train = [\n",
    "        A.Transpose(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightness(limit=0.2, p=0.75),\n",
    "        A.RandomContrast(limit=0.2, p=0.75),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(blur_limit=5),\n",
    "            A.MedianBlur(blur_limit=5),\n",
    "            A.GaussianBlur(blur_limit=5),\n",
    "            A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "        ], p=0.7),\n",
    "\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(distort_limit=1.0),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "            A.ElasticTransform(alpha=3),\n",
    "        ], p=0.7),\n",
    "\n",
    "        A.CLAHE(clip_limit=4.0, p=0.7),\n",
    "        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
    "        A.Resize(image_size, image_size)\n",
    "    ]\n",
    "    if cut_out:\n",
    "        transforms_train.append(A.Cutout(max_h_size=int(image_size * 0.375), max_w_size=int(image_size * 0.375), num_holes=1, p=0.7))\n",
    "    norm = A.Normalize()\n",
    "    if no_norm:\n",
    "        norm = A.Normalize(mean=0, std=1)\n",
    "    transforms_train.append(norm)\n",
    "    return A.Compose(transforms_train)\n",
    "\n",
    "def get_default_val_transform(image_size=224):\n",
    "    return A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def split_df_to_cat_num_df(df):\n",
    "    text_fields = ['image_id', 'lesion_id', 'dx', 'dx_type', 'localization', 'path', 'label_fullstr', 'sex']\n",
    "    text_df = df.loc[:, df.columns.isin(text_fields)].copy()\n",
    "    numerical_df = df.drop(columns = text_fields)\n",
    "\n",
    "    image_id_cat = pd.Categorical(df['image_id'])\n",
    "    text_df['img_id'] = image_id_cat.codes\n",
    "    numerical_df['img_id']=image_id_cat.codes\n",
    "    y = numerical_df['label_index']\n",
    "    numerical_df = numerical_df.drop(columns=['label_index'])\n",
    "    \n",
    "    return text_df, numerical_df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def undersampling_df(df):\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    X_resampled, y_resampled = rus.fit_resample(df.drop(columns=['label_index']), df['label_index'])\n",
    "    X_resampled['label_index'] = y_resampled\n",
    "    return X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def oversampling_df(df):\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled, y_resampled = ros.fit_resample(df.drop(columns=['label_index']), df['label_index'])\n",
    "    X_resampled['label_index'] = y_resampled\n",
    "    return X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def oversampling_not_flat_df(df, data_aug_rate=None):\n",
    "    if not data_aug_rate:\n",
    "        data_aug_rate = [15,10,5,50,0,5,40]\n",
    "    for i in range(7):\n",
    "        if data_aug_rate[i]:\n",
    "            df=df.append([df.loc[df['label_index'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vascular lesions                 110\n",
       "Melanoma                         110\n",
       "Dermatofibroma                   110\n",
       "Melanocytic nevi                 110\n",
       "Actinic keratoses                110\n",
       "Basal cell carcinoma             110\n",
       "Benign keratosis-like lesions    110\n",
       "Name: label_fullstr, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PathConfig.CSV_PATH)\n",
    "train_df, valid_df, labels = preprocess_df(df, 0.2)\n",
    "train_df = undersampling_df(train_df)\n",
    "train_df['label_fullstr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actinic keratoses                5829\n",
       "Melanoma                         5829\n",
       "Basal cell carcinoma             5829\n",
       "Vascular lesions                 5829\n",
       "Melanocytic nevi                 5829\n",
       "Benign keratosis-like lesions    5829\n",
       "Dermatofibroma                   5829\n",
       "Name: label_fullstr, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PathConfig.CSV_PATH)\n",
    "train_df, valid_df, labels = preprocess_df(df, 0.2)\n",
    "train_df = oversampling_df(train_df)\n",
    "train_df['label_fullstr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5829\n",
       "5    1061\n",
       "2    1012\n",
       "1     472\n",
       "0     300\n",
       "6     128\n",
       "3     110\n",
       "Name: label_index, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PathConfig.CSV_PATH)\n",
    "train_df, valid_df, labels = preprocess_df(df, 0.2)\n",
    "train_df[\"label_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melanocytic nevi                 5829\n",
       "Dermatofibroma                   5500\n",
       "Melanoma                         5305\n",
       "Vascular lesions                 5120\n",
       "Benign keratosis-like lesions    5060\n",
       "Basal cell carcinoma             4720\n",
       "Actinic keratoses                4500\n",
       "Name: label_fullstr, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PathConfig.CSV_PATH)\n",
    "train_df, valid_df, labels = preprocess_df(df, 0.2)\n",
    "train_df = oversampling_not_flat_df(train_df)\n",
    "train_df['label_fullstr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdvancedHairAugmentation:\n",
    "    \"\"\"\n",
    "    Impose an image of a hair to the target image\n",
    "\n",
    "    Args:\n",
    "        hairs (int): maximum number of hairs to impose\n",
    "        hairs_folder (str): path to the folder with hairs images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hairs: int = 5, hairs_folder: str = \"\"):\n",
    "        self.hairs = hairs\n",
    "        self.hairs_folder = hairs_folder\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to draw hairs on.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Image with drawn hairs.\n",
    "        \"\"\"\n",
    "        n_hairs = random.randint(0, self.hairs)\n",
    "        \n",
    "        if not n_hairs:\n",
    "            return img\n",
    "        \n",
    "        height, width, _ = img.shape  # target image width and height\n",
    "        hair_images = [im for im in os.listdir(self.hairs_folder) if 'png' in im]\n",
    "        \n",
    "        for _ in range(n_hairs):\n",
    "            hair = cv2.imread(os.path.join(self.hairs_folder, random.choice(hair_images)))\n",
    "            hair = cv2.flip(hair, random.choice([-1, 0, 1]))\n",
    "            hair = cv2.rotate(hair, random.choice([0, 1, 2]))\n",
    "\n",
    "            \n",
    "            h_height, h_width, _ = hair.shape  # hair image width and height\n",
    "            if img.shape[0] < hair.shape[0] or img.shape[1] < hair.shape[1]:\n",
    "                hair = cv2.resize(hair, (int(width*0.8), int(height*0.8)))\n",
    "            h_height, h_width, _ = hair.shape  # hair image width and height\n",
    "            \n",
    "            roi_ho = random.randint(0, img.shape[0] - hair.shape[0])\n",
    "            roi_wo = random.randint(0, img.shape[1] - hair.shape[1])\n",
    "            roi = img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width]\n",
    "\n",
    "            # Creating a mask and inverse mask\n",
    "            img2gray = cv2.cvtColor(hair, cv2.COLOR_BGR2GRAY)\n",
    "            ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "            mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "            # Now black-out the area of hair in ROI\n",
    "            img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "            # Take only region of hair from hair image.\n",
    "            hair_fg = cv2.bitwise_and(hair, hair, mask=mask)\n",
    "\n",
    "            # Put hair in ROI and modify the target image\n",
    "            dst = cv2.add(img_bg, hair_fg)\n",
    "\n",
    "            img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width] = dst\n",
    "                \n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(hairs={self.hairs}, hairs_folder=\"{self.hairs_folder}\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DrawHair:\n",
    "    \"\"\"\n",
    "    Draw a random number of pseudo hairs\n",
    "\n",
    "    Args:\n",
    "        hairs (int): maximum number of hairs to draw\n",
    "        width (tuple): possible width of the hair in pixels\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hairs:int = 4, width:tuple = (1, 2)):\n",
    "        self.hairs = hairs\n",
    "        self.width = width\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to draw hairs on.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Image with drawn hairs.\n",
    "        \"\"\"\n",
    "        if not self.hairs:\n",
    "            return img\n",
    "        \n",
    "        width, height, _ = img.shape\n",
    "        \n",
    "        for _ in range(random.randint(0, self.hairs)):\n",
    "            # The origin point of the line will always be at the top half of the image\n",
    "            origin = (random.randint(0, width), random.randint(0, height // 2))\n",
    "            # The end of the line \n",
    "            end = (random.randint(0, width), random.randint(0, height))\n",
    "            color = (0, 0, 0)  # color of the hair. Black.\n",
    "            cv2.line(img, origin, end, color, random.randint(self.width[0], self.width[1]))\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(hairs={self.hairs}, width={self.width})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Microscope:\n",
    "    \"\"\"\n",
    "    Cutting out the edges around the center circle of the image\n",
    "    Imitating a picture, taken through the microscope\n",
    "\n",
    "    Args:\n",
    "        p (float): probability of applying an augmentation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p: float = 0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to apply transformation to.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Image with transformation.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:\n",
    "            circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8), # image placeholder\n",
    "                        (img.shape[1]//2, img.shape[0]//2), # center point of circle\n",
    "                        random.randint(img.shape[1]//2 - 3, img.shape[1]//2 + 15), # radius\n",
    "                        (0, 0, 0), # color\n",
    "                        -1)\n",
    "\n",
    "            mask = circle - 255\n",
    "            img = np.multiply(img, mask)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(p={self.p})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gen_new_dts(data_gen_aug=None):\n",
    "    save_path = '/Work/Workspace/ML/HAM10000/aug/images/'\n",
    "    if data_gen_aug is None:\n",
    "        data_gen_aug = [5, 5, 3, 10, 0, 3, 10]\n",
    "    df = pd.read_csv(PathConfig.CSV_PATH)\n",
    "    train_df, valid_df, labels = preprocess_df(df, 0.2)\n",
    "    t1 = transforms.Compose([\n",
    "        AdvancedHairAugmentation(8,hairs_folder='/Work/Workspace/ML/HAM10000/data/black_hair/'),\n",
    "        Microscope(p=0.5),\n",
    "    ])\n",
    "    t2 = transforms.Compose([\n",
    "        DrawHair(8),\n",
    "        Microscope(p=0.5),\n",
    "    ])\n",
    "    ts = [t1,t1,t2]\n",
    "    for index, row in train_df.iterrows():\n",
    "        label_idx = row['label_index']\n",
    "        if data_gen_aug[label_idx]:\n",
    "            for i in range(data_gen_aug[label_idx]):\n",
    "                path = row['path']\n",
    "                image_id = row['image_id'] + '_' + str(i)\n",
    "                new_path = save_path + image_id + '.jpg'\n",
    "                \n",
    "                image = cv2.imread(path)\n",
    "                # Generate augment image\n",
    "                idx = random.randint(0,2)\n",
    "                tfs = ts[idx](image)\n",
    "                \n",
    "                # Add to dataframe\n",
    "                new_row = row.copy()\n",
    "                new_row[\"image_id\"] = image_id\n",
    "                new_row[\"path\"] = new_path\n",
    "                train_df = train_df.append(new_row)\n",
    "                # save\n",
    "                cv2.imwrite(new_path, tfs)\n",
    "    # Save train_df, valid_df to csv\n",
    "    train_df = train_df.reset_index()\n",
    "    train_df = train_df.drop(columns=['index','path'])\n",
    "    valid_df = valid_df.drop(columns=['path'])\n",
    "    \n",
    "    train_df.to_csv('/Work/Workspace/ML/HAM10000/aug/train.csv', index=False)\n",
    "    valid_df.to_csv('/Work/Workspace/ML/HAM10000/aug/valid.csv', index=False)\n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = gen_new_dts()\n",
    "train_df[train_df[\"lesion_id\"] == \"HAM_0000118\"]\n",
    "\n",
    "train_df = train_df.reset_index()\n",
    "train_df = train_df.drop(columns=['index','path'])\n",
    "valid_df = valid_df.drop(columns=['path'])\n",
    "\n",
    "train_df.to_csv('/Work/Workspace/ML/HAM10000/aug/train.csv', index=False)\n",
    "valid_df.to_csv('/Work/Workspace/ML/HAM10000/aug/valid.csv', index=False)\n",
    "\n",
    "train_df['label_fullstr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_class_weights(target):\n",
    "    class_sample_count = np.unique(target, return_counts=True)[1]\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = weight[target]\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    return weight, samples_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00333333, 0.00211864, 0.00098814, 0.00909091, 0.00017156,\n",
       "       0.00094251, 0.0078125 ])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/termanteus/Downloads/HAM10000/HAM10000_metadata.csv\")\n",
    "train_df, valid_df, labels = preprocess_df(df, 0.2)\n",
    "y = train_df['label_index']\n",
    "class_weight, samples_weight = get_class_weights(y)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5829\n",
       "5    1061\n",
       "2    1012\n",
       "1     472\n",
       "0     300\n",
       "6     128\n",
       "3     110\n",
       "Name: label_index, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label_index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted utils_dataset.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script('utils_dataset.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
