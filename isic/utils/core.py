# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/utils.ipynb (unless otherwise specified).

__all__ = ['listify', 'is_listy', 'camel2snake', 'snakify_class_name', 'get_default_device', 'unsqueeze', 'reduce_loss',
           'NoneReduce', 'even_mults', 'generate_val_steps', 'format_time', 'first', 'apply', 'to_detach',
           'PrettyString', 'set_if_none']

# Cell
import numpy as np
import torch.nn as nn

from functools import partial
from collections import Iterable
from collections.abc import Generator
import re

import torch

# Cell
def listify(o):
    "Listify object, wrap that object with a list if need."
    if o is None: return []
    if isinstance(o, list): return o
    if isinstance(o, str): return o
    if isinstance(o, Iterable): return list(o)
    return [o]

# Cell
def is_listy(x):
    "`isinstance(x, (tuple,list,L))`"
    return isinstance(x, (tuple, list, slice, Generator))

# Cell
_camel_re1 = re.compile('(.)([A-Z][a-z]+)')
_camel_re2 = re.compile('([a-z0-9])([A-Z])')


def camel2snake(name):
    "CamelChar to camel_char"
    s1 = re.sub(_camel_re1, r'\1_\2', name)
    return re.sub(_camel_re2, r'\1_\2', s1).lower()

# Cell
def snakify_class_name(obj, cls_name):
    "Get class name then snakify it"
    return camel2snake(re.sub(rf'{cls_name}$', '', obj.__class__.__name__) or cls_name.lower())

# Cell
def get_default_device(use_cuda=None):
    "Return or set default device; `use_cuda`: None - CUDA if available; True - error if not availabe; False - CPU"
    b_GPU = use_cuda or (torch.cuda.is_available() and use_cuda is None)
    assert torch.cuda.is_available() or not b_GPU
    return torch.device(torch.cuda.current_device()) if b_GPU else torch.device('cpu')

# Cell
def unsqueeze(x, dim=-1, n=1):
    "Same as `torch.unsqueeze` but can add `n` dims"
    for _ in range(n): x = x.unsqueeze(dim)
    return x

# Cell
def reduce_loss(loss, reduction='mean'):
    "Manipulate loss with option `reduction` type."
    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss

# Cell
class NoneReduce():
    "A context manager to evaluate `loss_func` with none reduce."
    def __init__(self, loss_func): self.loss_func,self.old_red = loss_func,None

    def __enter__(self):
        if hasattr(self.loss_func, 'reduction'):
            self.old_red = self.loss_func.reduction
            self.loss_func.reduction = 'none'
            return self.loss_func
        else: return partial(self.loss_func, reduction='none')

    def __exit__(self, type, value, traceback):
        if self.old_red is not None: self.loss_func.reduction = self.old_red

# Cell
def even_mults(start, stop, n):
    "Build log-stepped array from `start` to `stop` in `n` steps."
    if n==1: return stop
    mult = stop/start
    step = mult**(1/(n-1))
    return np.array([start*(step**i) for i in range(n)])

# Cell
def generate_val_steps(val, n):
    "Generate `n` value, if n is slice, will generate a log-stepped array depends on `val`"
    if isinstance(val, slice):
        if val.start:
            val = even_mults(val.start, val.stop, n)
        else:
            val = [val.stop/10] * (n - 1) + [val.stop]
    vs = listify(val)
    if len(vs) == 1:
        vs = vs * n
    return vs

# Cell
def format_time(t):
    "Format `t` (in seconds) to (h):mm:ss"
    t = int(t)
    h,m,s = t//3600, (t//60)%60, t%60
    if h!= 0: return f'{h}:{m:02d}:{s:02d}'
    else:     return f'{m:02d}:{s:02d}'

# Cell
def first(x):
    "First element of `x`, or None if missing"
    try: return next(iter(x))
    except StopIteration: return None

# Cell
def apply(func, x, *args, **kwargs):
    "Apply `func` recursively to `x`, passing on args"
    if is_listy(x): return type(x)([apply(func, o, *args, **kwargs) for o in x])
    if isinstance(x,dict):  return {k: apply(func, v, *args, **kwargs) for k,v in x.items()}
    res = func(x, *args, **kwargs)
    return res

# Cell
def to_detach(b, cpu=True):
    "Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`."
    def _inner(x, cpu=True, gather=True):
        if not isinstance(x, torch.Tensor): return x
        x = x.detach()
        return x.cpu() if cpu else x
    return apply(_inner, b, cpu=cpu)

# Cell
class PrettyString(str):
    "Little hack to get strings to show properly in Jupyter."
    def __repr__(self): return self

# Cell
def set_if_none(obj, attrib, val):
