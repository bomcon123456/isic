# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/layers.ipynb (unless otherwise specified).

__all__ = ['AdaptiveConcatPool2d', 'MixLoss']

# Cell
import torch
import torch.nn as nn

from .utils import reduce_loss, NoneReduce

# Cell
class AdaptiveConcatPool2d(nn.Module):
    def __init__(self, sz=1):
        super().__init__()
        self.output_size = sz
        self.ap = nn.AdaptiveAvgPool2d(sz)
        self.mp = nn.AdaptiveMaxPool2d(sz)

    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)

# Cell
class MixLoss(nn.Module):
    def __init__(self, old_lf, mixup_cb):
        super().__init__()
        self.old_lf = old_lf
        self.mixup_cb = mixup_cb

    def forward(self, pred, yb):
        if self.mixup_cb.pl_module.testing: return self.old_lf(pred, yb)
        with NoneReduce(self.old_lf) as lf:
            self.mixup_cb.yb_1 = self.mixup_cb.yb_1.to(pred.device)
            self.mixup_cb.lam = self.mixup_cb.lam.to(pred.device)
            loss = torch.lerp(lf(pred, self.mixup_cb.yb_1), lf(pred,yb), self.mixup_cb.lam)
        return reduce_loss(loss, getattr(self.old_lf, 'reduction', 'mean'))